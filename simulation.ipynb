{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "df = pd.read_csv(\"./data/dataset.csv\").iloc[:, 1:].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, valid = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "predictor = TabularPredictor.load(\"./Models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기존 데이터 분포와 노이즈를 준 데이터의 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_to_use = [\n",
    "    \"EX1.H4_PV\",\n",
    "    \"EX1.H2O_PV\",\n",
    "    \"EX1.MELT_P_PV\",\n",
    "    \"EX1.H3_PV\",\n",
    "    \"EX5.MELT_TEMP\",\n",
    "    \"EX1.H2_PV\",\n",
    "    \"EX4.MELT_TEMP\",\n",
    "    \"EX1.Z3_PV\",\n",
    "    \"EX2.MELT_TEMP\",\n",
    "    \"EX3.MELT_TEMP\",\n",
    "    \"EX1.MD_TQ\",\n",
    "]\n",
    "og_data = train.loc[:, train.columns.difference(not_to_use)].iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_hist(df):\n",
    "    num_features = len(df.columns)\n",
    "\n",
    "    nrows = 2\n",
    "    ncols = (num_features + nrows - 1) // nrows\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 4 * nrows))\n",
    "\n",
    "    for idx, feature in enumerate(df.columns):\n",
    "        row = idx // ncols\n",
    "        col = idx % ncols\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        data = df.loc[:, feature].values\n",
    "\n",
    "        ax.hist(data, bins=1000, color=\"skyblue\", edgecolor=\"black\", alpha=0.7)\n",
    "        title = ax.set_title(f\"Histogram of {feature}\")\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "    total_subplots = nrows * ncols\n",
    "    if total_subplots > num_features:\n",
    "        for i in range(num_features, total_subplots):\n",
    "            row = i // ncols\n",
    "            col = i % ncols\n",
    "            axes[row, col].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_hist(og_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규 분포 노이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# 예: 정규분포 적합\n",
    "mu, std = stats.norm.fit(og_data)\n",
    "\n",
    "noise = np.random.normal(loc=mu, scale=std, size=og_data.shape)\n",
    "noisy_data = (og_data + noise) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_hist(noisy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KDE 노이즈\n",
    "\n",
    "데이터 분포를 확인했을 때, 특정 분포로 적합하기 어려우므로, KDE 노이즈 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "kde = KernelDensity(kernel=\"gaussian\", bandwidth=0.5).fit(og_data)\n",
    "\n",
    "\n",
    "\n",
    "noise = kde.sample(n_samples=og_data.shape[0])\n",
    "noise = pd.DataFrame(noise, columns=og_data.columns)\n",
    "\n",
    "\n",
    "noisy_data = (og_data + noise) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_hist(noisy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSGA 시뮬레이션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "not_to_use = [\n",
    "    \"EX1.H4_PV\",\n",
    "    \"EX1.H2O_PV\",\n",
    "    \"EX1.MELT_P_PV\",\n",
    "    \"EX1.H3_PV\",\n",
    "    \"EX5.MELT_TEMP\",\n",
    "    \"EX1.H2_PV\",\n",
    "    \"EX4.MELT_TEMP\",\n",
    "    \"EX1.Z3_PV\",\n",
    "    \"EX2.MELT_TEMP\",\n",
    "    \"EX3.MELT_TEMP\",\n",
    "    \"EX1.MD_TQ\",\n",
    "    \"passorfail\",\n",
    "]\n",
    "simulation_cols = train.columns.difference(not_to_use)\n",
    "\n",
    "\n",
    "def modify_data_based_on_bounds(valid: pd.DataFrame, bounds: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    각 컬럼에 대해 원본 구간 [L, U]를 계산한 후,\n",
    "      new_lower = L + factor_lower * (U - L)\n",
    "      new_upper = L + factor_upper * (U - L)\n",
    "    의 새로운 구간을 결정합니다.\n",
    "\n",
    "    이후 해당 구간으로 정규화 → 로짓 변환 → KDE 샘플링 → 역변환을 적용하여\n",
    "    노이즈가 포함된 데이터를 생성합니다.\n",
    "\n",
    "    bounds 딕셔너리는 각 컬럼별로 (factor_lower, factor_upper)를 제공합니다.\n",
    "    \"\"\"\n",
    "    df_mod = valid.copy()\n",
    "    eps = 1e-6  # 0 또는 1이 되는 것을 방지\n",
    "\n",
    "    for col in df_mod.columns:\n",
    "        # bounds가 정의된 컬럼만 수정 (나머지는 그대로)\n",
    "        if col not in bounds:\n",
    "            continue\n",
    "        if col in not_to_use:\n",
    "            continue\n",
    "\n",
    "        x = df_mod[col].astype(float).values\n",
    "        orig_lower = np.min(x)\n",
    "        orig_upper = np.max(x)\n",
    "        orig_range = orig_upper - orig_lower\n",
    "        if orig_range <= 0:\n",
    "            continue\n",
    "\n",
    "        # trial에서 제시한 상대적 비율값 (factor_lower, factor_upper)\n",
    "        factor_lower, factor_upper = bounds[col]\n",
    "        new_lower = orig_lower + factor_lower * orig_range\n",
    "        new_upper = orig_lower + factor_upper * orig_range\n",
    "\n",
    "        if new_lower >= new_upper:\n",
    "            continue\n",
    "\n",
    "        # [new_lower, new_upper] 구간으로 정규화 및 클리핑\n",
    "        x_norm = (x - new_lower) / (new_upper - new_lower)\n",
    "        x_norm = np.clip(x_norm, eps, 1 - eps)\n",
    "\n",
    "        # 로짓 변환\n",
    "        y = np.log(x_norm / (1 - x_norm)).reshape(-1, 1)\n",
    "\n",
    "        # KDE를 이용한 노이즈 추가: y 공간에서 원본과 동일한 수의 샘플 생성\n",
    "        kde = KernelDensity(kernel=\"gaussian\", bandwidth=0.5).fit(y)\n",
    "        noise = kde.sample(n_samples=len(x))\n",
    "        # 역로짓 변환 및 원본 스케일 복원\n",
    "        x_sim_norm = 1 / (1 + np.exp(-noise))\n",
    "        x_sim = x_sim_norm * (new_upper - new_lower) + new_lower\n",
    "\n",
    "        df_mod[col] = (df_mod[col].values + x_sim) / 2\n",
    "    return df_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_bounds = []\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    global trial_bounds\n",
    "\n",
    "    bounds = {}\n",
    "    margin = 0.5  # 기본 구간의 ±20%까지 확장/축소 허용\n",
    "    for col in simulation_cols:\n",
    "        # 각 컬럼에 대해 두 개의 상대적 위치 값을 제안\n",
    "        r1 = trial.suggest_float(col + \"_bound1\", low=-margin, high=1 + margin)\n",
    "        r2 = trial.suggest_float(col + \"_bound2\", low=-margin, high=1 + margin)\n",
    "        factor_lower = min(r1, r2)\n",
    "        factor_upper = max(r1, r2)\n",
    "        bounds[col] = (factor_lower, factor_upper)\n",
    "\n",
    "    trial_bounds.append(bounds)\n",
    "\n",
    "    # [시뮬레이션 영역의 폭] 계산: 각 컬럼의 새 구간 폭의 합\n",
    "    sim_range_sum = 0\n",
    "    for col in simulation_cols:\n",
    "        x = train[col].astype(float).values\n",
    "        orig_lower = np.min(x)\n",
    "        orig_upper = np.max(x)\n",
    "        orig_range = orig_upper - orig_lower\n",
    "        factor_lower, factor_upper = bounds[col]\n",
    "        new_range = (factor_upper - factor_lower) * orig_range\n",
    "        sim_range_sum += new_range\n",
    "\n",
    "    # trial에서 제시한 bounds를 반영해 검증 데이터 변형\n",
    "    modified_val_features = modify_data_based_on_bounds(valid, bounds)\n",
    "\n",
    "    predictions = predictor.predict(modified_val_features)\n",
    "\n",
    "    acceptance_rate = 1 - (sum(predictions) / len(predictions))\n",
    "\n",
    "    # 다목적 최적화 대상 (각 목표에 대해 방향을 아래와 같이 설정)\n",
    "    # 1. acceptance_rate: 최대화\n",
    "    # 2. sim_range_sum: 최대화 (더 넓은 시뮬레이션 영역)\n",
    "    return acceptance_rate, sim_range_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna를 통한 상한/하한 최적화\n",
    "from optuna.samplers import NSGAIIISampler, NSGAIISampler\n",
    "\n",
    "study = optuna.create_study(\n",
    "    sampler=NSGAIISampler(population_size=10),\n",
    "    directions=[\n",
    "        \"maximize\",\n",
    "        \"maximize\",\n",
    "    ],\n",
    ")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# 최적의 상한/하한 값 확인\n",
    "print(\"Best trial len:\", len(study.best_trials))\n",
    "print(\"Best trial:\", study.best_trials[0].params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.io import show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "fig = optuna.visualization.plot_pareto_front(\n",
    "    study,\n",
    "    targets=lambda t: (t.values[0], t.values[1]),\n",
    "    target_names=[\"합격률\", \"새롭게 설정한 상/하한 범위의 합\"],\n",
    ")\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skcriteria import mkdm\n",
    "from skcriteria.madm import simple\n",
    "from skcriteria.agg import similarity\n",
    "from skcriteria.preprocessing import scalers\n",
    "\n",
    "pareto_solutions = []\n",
    "for trial in study.best_trials:\n",
    "    # trial의 모든 파라미터와 목표 값 (불량률 및 비용)을 함께 저장\n",
    "    solution = trial.params\n",
    "    solution[\"Defect_Rate\"] = trial.values[0]  # 불량률\n",
    "    solution[\"Cost\"] = trial.values[1]  # 비용\n",
    "    pareto_solutions.append(solution)\n",
    "\n",
    "pareto_df = pd.DataFrame(pareto_solutions)\n",
    "\n",
    "# 4. TOPSIS 적용\n",
    "# `Defect_Rate`는 최소화, `Cost`는 최대화가 목표이므로 각각의 목표 설정\n",
    "# 양의 이상적 솔루션으로 부터 가장 짧은 거리, 음의 이상적 솔루션으로 부터 가장 긴 거리\n",
    "criteria_data = pareto_df[[\"Defect_Rate\", \"Cost\"]].values\n",
    "criteria_names = [\"Defect_Rate\", \"Cost\"]\n",
    "criteria_min_max = [min, max]  # 최소화/최대화 설정\n",
    "\n",
    "# 데이터 스케일링 및 TOPSIS 모델 설정\n",
    "dm = mkdm(\n",
    "    matrix=criteria_data,\n",
    "    objectives=criteria_min_max,\n",
    "    criteria=criteria_names,\n",
    "    alternatives=pareto_df.index,  # trial 인덱스 사용\n",
    ")\n",
    "\n",
    "# 데이터 정규화 및 TOPSIS 적용\n",
    "scaler = scalers.SumScaler(target=\"both\")\n",
    "dm = scaler.transform(dm)\n",
    "topsis = similarity.TOPSIS()\n",
    "decision = topsis.evaluate(dm)\n",
    "\n",
    "# 결과 처리: 각 trial의 TOPSIS 점수 및 랭킹 추가\n",
    "pareto_df[\"TOPSIS_Score\"] = decision.e_.similarity  # 유사도 인덱스가 점수\n",
    "pareto_df[\"Rank\"] = pareto_df[\"TOPSIS_Score\"].rank(ascending=False)  # 내림차순으로 랭크\n",
    "\n",
    "# 최적 타협 해 선택\n",
    "optimal_solution = pareto_df.sort_values(by=\"TOPSIS_Score\", ascending=False).iloc[0]\n",
    "print(\"TOPSIS 최적 타협 해:\\n\", optimal_solution)\n",
    "\n",
    "# 전체 Pareto 해 집합과 TOPSIS 결과 표시\n",
    "print(\"Pareto 해 집합과 TOPSIS 결과:\\n\", pareto_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_dict = {}\n",
    "new_dict = {}\n",
    "for i, col in enumerate(simulation_cols):\n",
    "    col_min = df[col].min()\n",
    "    col_max = df[col].max()\n",
    "    origin_dict[col + \"상한\"] = col_max\n",
    "    origin_dict[col + \"하한\"] = col_min\n",
    "\n",
    "    range_ = col_max - col_min\n",
    "    factor_lower = min(optimal_solution.iloc[i], optimal_solution.iloc[i + 1])\n",
    "    factor_upper = max(optimal_solution.iloc[i], optimal_solution.iloc[i + 1])\n",
    "    new_dict[col + \"상한_new\"] = col_min + range_ * factor_upper\n",
    "    new_dict[col + \"하한_new\"] = col_min + range_ * factor_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(origin_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsga",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
